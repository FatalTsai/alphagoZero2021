{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import boston_housing\n",
    "from tensorflow.keras.layers import Activation,Dense,Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data,train_labels),(test_data,test_labels) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_data))\n",
    "print(type(train_labels))\n",
    "print(type(test_data))\n",
    "print(type(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13)\n",
      "(404,)\n",
      "(102, 13)\n",
      "(102,)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_data.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.23247e+00 0.00000e+00 8.14000e+00 0.00000e+00 5.38000e-01 6.14200e+00\n",
      "  9.17000e+01 3.97690e+00 4.00000e+00 3.07000e+02 2.10000e+01 3.96900e+02\n",
      "  1.87200e+01]\n",
      " [2.17700e-02 8.25000e+01 2.03000e+00 0.00000e+00 4.15000e-01 7.61000e+00\n",
      "  1.57000e+01 6.27000e+00 2.00000e+00 3.48000e+02 1.47000e+01 3.95380e+02\n",
      "  3.11000e+00]\n",
      " [4.89822e+00 0.00000e+00 1.81000e+01 0.00000e+00 6.31000e-01 4.97000e+00\n",
      "  1.00000e+02 1.33250e+00 2.40000e+01 6.66000e+02 2.02000e+01 3.75520e+02\n",
      "  3.26000e+00]\n",
      " [3.96100e-02 0.00000e+00 5.19000e+00 0.00000e+00 5.15000e-01 6.03700e+00\n",
      "  3.45000e+01 5.98530e+00 5.00000e+00 2.24000e+02 2.02000e+01 3.96900e+02\n",
      "  8.01000e+00]\n",
      " [3.69311e+00 0.00000e+00 1.81000e+01 0.00000e+00 7.13000e-01 6.37600e+00\n",
      "  8.84000e+01 2.56710e+00 2.40000e+01 6.66000e+02 2.02000e+01 3.91430e+02\n",
      "  1.46500e+01]]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15.2 42.3 50.  21.1 17.7]\n"
     ]
    }
   ],
   "source": [
    "print(train_labels[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = np.random.randint(0,404,size=404)\n",
    "train_data = train_data[order]\n",
    "train_labels = train_labels[order]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = train_data.mean(axis=0)\n",
    "std = train_data.std(axis=0)\n",
    "train_data = (train_data-mean)/std\n",
    "test_data = (test_data-mean)/std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.241522</td>\n",
       "      <td>-0.441868</td>\n",
       "      <td>0.960450</td>\n",
       "      <td>-0.262265</td>\n",
       "      <td>1.269218</td>\n",
       "      <td>0.166733</td>\n",
       "      <td>0.765555</td>\n",
       "      <td>-0.638329</td>\n",
       "      <td>1.654058</td>\n",
       "      <td>1.517334</td>\n",
       "      <td>0.818419</td>\n",
       "      <td>0.308812</td>\n",
       "      <td>0.531138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.437395</td>\n",
       "      <td>-0.441868</td>\n",
       "      <td>0.960450</td>\n",
       "      <td>3.812933</td>\n",
       "      <td>0.575244</td>\n",
       "      <td>1.257836</td>\n",
       "      <td>0.976886</td>\n",
       "      <td>-1.228374</td>\n",
       "      <td>1.654058</td>\n",
       "      <td>1.517334</td>\n",
       "      <td>0.818419</td>\n",
       "      <td>0.387326</td>\n",
       "      <td>-1.451697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.377543</td>\n",
       "      <td>-0.441868</td>\n",
       "      <td>-0.754267</td>\n",
       "      <td>-0.262265</td>\n",
       "      <td>-0.474181</td>\n",
       "      <td>1.776831</td>\n",
       "      <td>0.016629</td>\n",
       "      <td>0.262479</td>\n",
       "      <td>-0.175482</td>\n",
       "      <td>-0.619353</td>\n",
       "      <td>-0.510220</td>\n",
       "      <td>0.364990</td>\n",
       "      <td>-1.206441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.440417</td>\n",
       "      <td>-0.441868</td>\n",
       "      <td>-1.156289</td>\n",
       "      <td>-0.262265</td>\n",
       "      <td>-0.626517</td>\n",
       "      <td>0.348836</td>\n",
       "      <td>-0.187287</td>\n",
       "      <td>-0.271841</td>\n",
       "      <td>-0.861559</td>\n",
       "      <td>-0.839569</td>\n",
       "      <td>-0.320414</td>\n",
       "      <td>0.388793</td>\n",
       "      <td>-0.641104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.411366</td>\n",
       "      <td>-0.441868</td>\n",
       "      <td>-0.221120</td>\n",
       "      <td>-0.262265</td>\n",
       "      <td>-0.161046</td>\n",
       "      <td>-0.249070</td>\n",
       "      <td>0.713650</td>\n",
       "      <td>-0.402574</td>\n",
       "      <td>-0.632867</td>\n",
       "      <td>-0.637208</td>\n",
       "      <td>-0.035706</td>\n",
       "      <td>0.435270</td>\n",
       "      <td>-0.237886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0  0.241522 -0.441868  0.960450 -0.262265  1.269218  0.166733  0.765555   \n",
       "1  0.437395 -0.441868  0.960450  3.812933  0.575244  1.257836  0.976886   \n",
       "2 -0.377543 -0.441868 -0.754267 -0.262265 -0.474181  1.776831  0.016629   \n",
       "3 -0.440417 -0.441868 -1.156289 -0.262265 -0.626517  0.348836 -0.187287   \n",
       "4 -0.411366 -0.441868 -0.221120 -0.262265 -0.161046 -0.249070  0.713650   \n",
       "\n",
       "        DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
       "0 -0.638329  1.654058  1.517334  0.818419  0.308812  0.531138  \n",
       "1 -1.228374  1.654058  1.517334  0.818419  0.387326 -1.451697  \n",
       "2  0.262479 -0.175482 -0.619353 -0.510220  0.364990 -1.206441  \n",
       "3 -0.271841 -0.861559 -0.839569 -0.320414  0.388793 -0.641104  \n",
       "4 -0.402574 -0.632867 -0.637208 -0.035706  0.435270 -0.237886  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = ['CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B','LSTAT']\n",
    "df = pd.DataFrame(train_data,columns=column_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64,activation='relu',input_shape=(13,)))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse',optimizer=Adam(learning_rate=0.001),metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 510.3318 - mae: 21.0192 - val_loss: 476.4509 - val_mae: 19.8696\n",
      "Epoch 2/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 469.0966 - mae: 20.0334 - val_loss: 430.4621 - val_mae: 18.7300\n",
      "Epoch 3/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 416.9868 - mae: 18.8007 - val_loss: 372.9048 - val_mae: 17.2050\n",
      "Epoch 4/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 351.0899 - mae: 17.1124 - val_loss: 299.6221 - val_mae: 15.0990\n",
      "Epoch 5/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 269.4030 - mae: 14.7273 - val_loss: 215.0798 - val_mae: 12.3531\n",
      "Epoch 6/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 179.0388 - mae: 11.6805 - val_loss: 137.0416 - val_mae: 9.1432\n",
      "Epoch 7/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 105.2681 - mae: 8.4001 - val_loss: 90.1064 - val_mae: 7.0907\n",
      "Epoch 8/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 65.2109 - mae: 6.2128 - val_loss: 69.4780 - val_mae: 6.0684\n",
      "Epoch 9/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 49.5532 - mae: 5.2715 - val_loss: 56.6851 - val_mae: 5.4892\n",
      "Epoch 10/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 39.8286 - mae: 4.7161 - val_loss: 45.8717 - val_mae: 4.9539\n",
      "Epoch 11/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 32.3072 - mae: 4.2033 - val_loss: 38.3903 - val_mae: 4.5063\n",
      "Epoch 12/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 27.4914 - mae: 3.8579 - val_loss: 33.1854 - val_mae: 4.1667\n",
      "Epoch 13/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 24.2997 - mae: 3.5802 - val_loss: 30.3225 - val_mae: 3.9205\n",
      "Epoch 14/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 21.6543 - mae: 3.3912 - val_loss: 27.1931 - val_mae: 3.7334\n",
      "Epoch 15/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 19.7569 - mae: 3.3152 - val_loss: 24.7227 - val_mae: 3.6985\n",
      "Epoch 16/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 18.5493 - mae: 3.2548 - val_loss: 23.1451 - val_mae: 3.6619\n",
      "Epoch 17/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 17.2454 - mae: 3.1421 - val_loss: 22.0629 - val_mae: 3.5511\n",
      "Epoch 18/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 16.2656 - mae: 3.0125 - val_loss: 21.1190 - val_mae: 3.4151\n",
      "Epoch 19/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 15.3811 - mae: 2.9052 - val_loss: 20.2863 - val_mae: 3.2998\n",
      "Epoch 20/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 14.7203 - mae: 2.8332 - val_loss: 19.3929 - val_mae: 3.2184\n",
      "Epoch 21/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 14.0513 - mae: 2.7963 - val_loss: 18.5772 - val_mae: 3.1689\n",
      "Epoch 22/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 13.3866 - mae: 2.7268 - val_loss: 17.7565 - val_mae: 3.1672\n",
      "Epoch 23/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 12.8389 - mae: 2.6549 - val_loss: 17.4930 - val_mae: 3.1527\n",
      "Epoch 24/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 12.3615 - mae: 2.5848 - val_loss: 17.0048 - val_mae: 3.0648\n",
      "Epoch 25/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 12.1100 - mae: 2.5335 - val_loss: 16.6560 - val_mae: 3.0042\n",
      "Epoch 26/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 11.6728 - mae: 2.5137 - val_loss: 15.6873 - val_mae: 2.9724\n",
      "Epoch 27/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 11.3907 - mae: 2.4958 - val_loss: 15.2811 - val_mae: 2.9330\n",
      "Epoch 28/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 11.0042 - mae: 2.4416 - val_loss: 14.9835 - val_mae: 2.8961\n",
      "Epoch 29/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 10.7135 - mae: 2.3959 - val_loss: 14.5938 - val_mae: 2.8703\n",
      "Epoch 30/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 10.4579 - mae: 2.3533 - val_loss: 14.3083 - val_mae: 2.8352\n",
      "Epoch 31/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 10.2279 - mae: 2.3196 - val_loss: 14.1322 - val_mae: 2.7941\n",
      "Epoch 32/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 10.1055 - mae: 2.3215 - val_loss: 13.6643 - val_mae: 2.7658\n",
      "Epoch 33/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 9.9022 - mae: 2.3039 - val_loss: 13.5489 - val_mae: 2.7373\n",
      "Epoch 34/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 9.7802 - mae: 2.2740 - val_loss: 14.9872 - val_mae: 2.7735\n",
      "Epoch 35/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 9.8810 - mae: 2.2694 - val_loss: 14.4350 - val_mae: 2.7006\n",
      "Epoch 36/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 9.3441 - mae: 2.2234 - val_loss: 13.8820 - val_mae: 2.7122\n",
      "Epoch 37/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 9.1200 - mae: 2.1930 - val_loss: 13.4119 - val_mae: 2.6871\n",
      "Epoch 38/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 9.0828 - mae: 2.1794 - val_loss: 13.2847 - val_mae: 2.6699\n",
      "Epoch 39/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 8.8058 - mae: 2.1414 - val_loss: 12.7698 - val_mae: 2.6179\n",
      "Epoch 40/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 8.8880 - mae: 2.1524 - val_loss: 11.8300 - val_mae: 2.5889\n",
      "Epoch 41/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 8.4950 - mae: 2.1108 - val_loss: 11.8446 - val_mae: 2.5655\n",
      "Epoch 42/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 8.5776 - mae: 2.1243 - val_loss: 12.1534 - val_mae: 2.5644\n",
      "Epoch 43/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 8.5067 - mae: 2.1168 - val_loss: 11.7391 - val_mae: 2.5109\n",
      "Epoch 44/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 8.3514 - mae: 2.0698 - val_loss: 12.2493 - val_mae: 2.5739\n",
      "Epoch 45/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 8.3137 - mae: 2.0404 - val_loss: 11.7976 - val_mae: 2.5012\n",
      "Epoch 46/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 8.0650 - mae: 2.0297 - val_loss: 11.3933 - val_mae: 2.4659\n",
      "Epoch 47/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 8.0990 - mae: 2.0622 - val_loss: 10.9650 - val_mae: 2.4320\n",
      "Epoch 48/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 7.7884 - mae: 2.0154 - val_loss: 11.0070 - val_mae: 2.4539\n",
      "Epoch 49/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 7.7477 - mae: 1.9963 - val_loss: 11.1082 - val_mae: 2.4637\n",
      "Epoch 50/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 7.6386 - mae: 1.9875 - val_loss: 11.1520 - val_mae: 2.4633\n",
      "Epoch 51/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 7.5602 - mae: 1.9842 - val_loss: 11.1633 - val_mae: 2.4471\n",
      "Epoch 52/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 7.4507 - mae: 1.9678 - val_loss: 10.9896 - val_mae: 2.4463\n",
      "Epoch 53/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 7.4462 - mae: 1.9584 - val_loss: 11.0065 - val_mae: 2.4220\n",
      "Epoch 54/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 7.3301 - mae: 1.9399 - val_loss: 10.8129 - val_mae: 2.4143\n",
      "Epoch 55/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 7.3093 - mae: 1.9381 - val_loss: 10.7275 - val_mae: 2.3914\n",
      "Epoch 56/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 7.2338 - mae: 1.9230 - val_loss: 10.8936 - val_mae: 2.3972\n",
      "Epoch 57/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 7.1773 - mae: 1.9064 - val_loss: 10.8455 - val_mae: 2.3971\n",
      "Epoch 58/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 7.0661 - mae: 1.9096 - val_loss: 11.6352 - val_mae: 2.4019\n",
      "Epoch 59/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 7.1867 - mae: 1.9150 - val_loss: 11.6847 - val_mae: 2.4084\n",
      "Epoch 60/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 7.1795 - mae: 1.9146 - val_loss: 11.3445 - val_mae: 2.4392\n",
      "Epoch 61/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 7.0856 - mae: 1.9005 - val_loss: 11.2650 - val_mae: 2.3916\n",
      "Epoch 62/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.9238 - mae: 1.8837 - val_loss: 11.0625 - val_mae: 2.3733\n",
      "Epoch 63/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.8519 - mae: 1.8615 - val_loss: 10.7660 - val_mae: 2.3881\n",
      "Epoch 64/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.8224 - mae: 1.8639 - val_loss: 10.7091 - val_mae: 2.3670\n",
      "Epoch 65/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.7510 - mae: 1.8467 - val_loss: 10.4782 - val_mae: 2.3631\n",
      "Epoch 66/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 7.6029 - mae: 1.9887 - val_loss: 9.6509 - val_mae: 2.4016\n",
      "Epoch 67/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 7.1377 - mae: 1.9346 - val_loss: 9.4561 - val_mae: 2.2963\n",
      "Epoch 68/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.7306 - mae: 1.8382 - val_loss: 9.7632 - val_mae: 2.2919\n",
      "Epoch 69/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.6663 - mae: 1.8288 - val_loss: 9.9431 - val_mae: 2.3174\n",
      "Epoch 70/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.5826 - mae: 1.8077 - val_loss: 9.9477 - val_mae: 2.3054\n",
      "Epoch 71/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.5217 - mae: 1.8072 - val_loss: 9.9672 - val_mae: 2.2606\n",
      "Epoch 72/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 6.4700 - mae: 1.8120 - val_loss: 9.8340 - val_mae: 2.2532\n",
      "Epoch 73/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 6.3909 - mae: 1.7946 - val_loss: 9.7237 - val_mae: 2.2748\n",
      "Epoch 74/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.3496 - mae: 1.7983 - val_loss: 9.7856 - val_mae: 2.2720\n",
      "Epoch 75/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 6.3040 - mae: 1.7835 - val_loss: 9.7332 - val_mae: 2.2734\n",
      "Epoch 76/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 6.2667 - mae: 1.7613 - val_loss: 9.8658 - val_mae: 2.2704\n",
      "Epoch 77/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.2346 - mae: 1.7585 - val_loss: 9.9127 - val_mae: 2.2560\n",
      "Epoch 78/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 6.1811 - mae: 1.7401 - val_loss: 9.7334 - val_mae: 2.2843\n",
      "Epoch 79/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 6.2407 - mae: 1.7468 - val_loss: 9.4957 - val_mae: 2.2595\n",
      "Epoch 80/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 6.3139 - mae: 1.7857 - val_loss: 9.6106 - val_mae: 2.2393\n",
      "Epoch 81/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.1354 - mae: 1.7410 - val_loss: 9.6235 - val_mae: 2.2760\n",
      "Epoch 82/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.0619 - mae: 1.7099 - val_loss: 9.6591 - val_mae: 2.2670\n",
      "Epoch 83/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 5.9623 - mae: 1.7107 - val_loss: 9.7924 - val_mae: 2.2330\n",
      "Epoch 84/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 5.9511 - mae: 1.6997 - val_loss: 9.5312 - val_mae: 2.2402\n",
      "Epoch 85/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 5.9228 - mae: 1.6974 - val_loss: 9.4711 - val_mae: 2.2355\n",
      "Epoch 86/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 5.9181 - mae: 1.6773 - val_loss: 9.4077 - val_mae: 2.2318\n",
      "Epoch 87/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 5.8731 - mae: 1.6686 - val_loss: 9.4068 - val_mae: 2.2146\n",
      "Epoch 88/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 5.8275 - mae: 1.6904 - val_loss: 9.3146 - val_mae: 2.2250\n",
      "Epoch 89/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 5.8624 - mae: 1.7100 - val_loss: 9.3015 - val_mae: 2.2074\n",
      "Epoch 90/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 5.7506 - mae: 1.6614 - val_loss: 9.4200 - val_mae: 2.2178\n",
      "Epoch 91/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 5.6925 - mae: 1.6432 - val_loss: 10.0873 - val_mae: 2.2024\n",
      "Epoch 92/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 5.7447 - mae: 1.6775 - val_loss: 9.9999 - val_mae: 2.2215\n",
      "Epoch 93/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 5.6480 - mae: 1.6901 - val_loss: 9.5925 - val_mae: 2.2416\n",
      "Epoch 94/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 5.6648 - mae: 1.6376 - val_loss: 9.4730 - val_mae: 2.2394\n",
      "Epoch 95/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 5.5308 - mae: 1.6284 - val_loss: 9.4174 - val_mae: 2.1943\n",
      "Epoch 96/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 5.4872 - mae: 1.6241 - val_loss: 9.2479 - val_mae: 2.2168\n",
      "Epoch 97/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 5.5401 - mae: 1.6218 - val_loss: 9.2179 - val_mae: 2.2173\n",
      "Epoch 98/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 5.4146 - mae: 1.5973 - val_loss: 9.2171 - val_mae: 2.1907\n",
      "Epoch 99/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 5.4843 - mae: 1.6307 - val_loss: 9.3050 - val_mae: 2.1913\n",
      "Epoch 100/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 5.4022 - mae: 1.5716 - val_loss: 9.2622 - val_mae: 2.1967\n",
      "Epoch 101/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 5.4009 - mae: 1.5864 - val_loss: 9.0827 - val_mae: 2.1969\n",
      "Epoch 102/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 5.3236 - mae: 1.5878 - val_loss: 9.1742 - val_mae: 2.1762\n",
      "Epoch 103/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 5.2960 - mae: 1.5879 - val_loss: 8.9733 - val_mae: 2.1516\n",
      "Epoch 104/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 5.2311 - mae: 1.5513 - val_loss: 9.0243 - val_mae: 2.1602\n",
      "Epoch 105/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 5.2510 - mae: 1.5587 - val_loss: 9.0303 - val_mae: 2.1362\n",
      "Epoch 106/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 5.2140 - mae: 1.5527 - val_loss: 8.7321 - val_mae: 2.1275\n",
      "Epoch 107/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 5.1341 - mae: 1.5593 - val_loss: 8.7386 - val_mae: 2.1423\n",
      "Epoch 108/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 5.2498 - mae: 1.5538 - val_loss: 9.2055 - val_mae: 2.1465\n",
      "Epoch 109/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 5.2371 - mae: 1.5821 - val_loss: 8.9370 - val_mae: 2.0978\n",
      "Epoch 110/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 5.0718 - mae: 1.5632 - val_loss: 8.8608 - val_mae: 2.1258\n",
      "Epoch 111/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 4.9992 - mae: 1.5207 - val_loss: 8.8252 - val_mae: 2.1280\n",
      "Epoch 112/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 4.9896 - mae: 1.5255 - val_loss: 8.7981 - val_mae: 2.1305\n",
      "Epoch 113/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 4.9466 - mae: 1.5236 - val_loss: 8.9954 - val_mae: 2.1562\n",
      "Epoch 114/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 4.9187 - mae: 1.5139 - val_loss: 9.0293 - val_mae: 2.1538\n",
      "Epoch 115/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 4.9425 - mae: 1.5211 - val_loss: 9.8826 - val_mae: 2.1656\n",
      "Epoch 116/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 5.1007 - mae: 1.5546 - val_loss: 9.6175 - val_mae: 2.1671\n",
      "Epoch 117/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 4.8782 - mae: 1.5206 - val_loss: 9.2958 - val_mae: 2.1835\n",
      "Epoch 118/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 4.8533 - mae: 1.5009 - val_loss: 9.1481 - val_mae: 2.1358\n",
      "Epoch 119/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 4.8337 - mae: 1.5264 - val_loss: 8.9000 - val_mae: 2.1216\n",
      "Epoch 120/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 4.9147 - mae: 1.4996 - val_loss: 8.7866 - val_mae: 2.1334\n",
      "Epoch 121/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 4.7467 - mae: 1.4534 - val_loss: 8.6151 - val_mae: 2.0896\n",
      "Epoch 122/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 4.7822 - mae: 1.5137 - val_loss: 8.6006 - val_mae: 2.0886\n",
      "Epoch 123/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 4.7256 - mae: 1.4458 - val_loss: 8.7752 - val_mae: 2.0995\n",
      "Epoch 124/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 4.7531 - mae: 1.4536 - val_loss: 8.5867 - val_mae: 2.0874\n",
      "Epoch 125/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 4.6150 - mae: 1.4456 - val_loss: 9.0972 - val_mae: 2.0892\n",
      "Epoch 126/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 4.9946 - mae: 1.5455 - val_loss: 9.5059 - val_mae: 2.0947\n",
      "Epoch 127/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 4.7218 - mae: 1.4817 - val_loss: 9.0102 - val_mae: 2.1393\n",
      "Epoch 128/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 4.6534 - mae: 1.4378 - val_loss: 8.8739 - val_mae: 2.0926\n",
      "Epoch 129/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 4.5558 - mae: 1.4333 - val_loss: 8.5357 - val_mae: 2.0866\n",
      "Epoch 130/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 4.6181 - mae: 1.4287 - val_loss: 8.5747 - val_mae: 2.0789\n",
      "Epoch 131/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 4.7888 - mae: 1.4853 - val_loss: 9.7385 - val_mae: 2.1189\n",
      "Epoch 132/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 4.6215 - mae: 1.4337 - val_loss: 9.0533 - val_mae: 2.1469\n",
      "Epoch 133/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 4.5396 - mae: 1.4596 - val_loss: 8.9832 - val_mae: 2.1151\n",
      "Epoch 134/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 4.4275 - mae: 1.4459 - val_loss: 8.7442 - val_mae: 2.0618\n",
      "Epoch 135/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 4.4374 - mae: 1.3825 - val_loss: 8.5232 - val_mae: 2.0428\n",
      "Epoch 136/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 4.4415 - mae: 1.4354 - val_loss: 8.4963 - val_mae: 2.0660\n",
      "Epoch 137/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 4.3707 - mae: 1.3791 - val_loss: 8.8327 - val_mae: 2.0568\n",
      "Epoch 138/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 4.3018 - mae: 1.3836 - val_loss: 8.6878 - val_mae: 2.0411\n",
      "Epoch 139/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 4.3148 - mae: 1.3826 - val_loss: 8.7805 - val_mae: 2.0479\n",
      "Epoch 140/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 4.2400 - mae: 1.3610 - val_loss: 8.5453 - val_mae: 2.0462\n",
      "Epoch 141/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 4.1709 - mae: 1.3776 - val_loss: 8.3503 - val_mae: 2.0130\n",
      "Epoch 142/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 4.1790 - mae: 1.3924 - val_loss: 8.1040 - val_mae: 2.0075\n",
      "Epoch 143/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 4.1462 - mae: 1.3591 - val_loss: 8.1768 - val_mae: 1.9983\n",
      "Epoch 144/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 4.0911 - mae: 1.3561 - val_loss: 8.2514 - val_mae: 2.0000\n",
      "Epoch 145/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 4.0333 - mae: 1.3490 - val_loss: 8.1022 - val_mae: 1.9886\n",
      "Epoch 146/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 4.0614 - mae: 1.3208 - val_loss: 8.1027 - val_mae: 1.9629\n",
      "Epoch 147/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 4.3387 - mae: 1.4603 - val_loss: 8.4755 - val_mae: 1.9887\n",
      "Epoch 148/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 4.1019 - mae: 1.3417 - val_loss: 8.2626 - val_mae: 2.0002\n",
      "Epoch 149/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 4.0923 - mae: 1.3728 - val_loss: 8.0540 - val_mae: 1.9847\n",
      "Epoch 150/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 4.1100 - mae: 1.3709 - val_loss: 7.9197 - val_mae: 1.9856\n",
      "Epoch 151/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 4.3641 - mae: 1.4906 - val_loss: 8.1767 - val_mae: 2.0237\n",
      "Epoch 152/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3.9864 - mae: 1.3613 - val_loss: 8.0340 - val_mae: 1.9729\n",
      "Epoch 153/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.9728 - mae: 1.3569 - val_loss: 7.9451 - val_mae: 1.9882\n",
      "Epoch 154/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.9122 - mae: 1.3449 - val_loss: 7.8427 - val_mae: 1.9510\n",
      "Epoch 155/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.8251 - mae: 1.2971 - val_loss: 7.6512 - val_mae: 1.9549\n",
      "Epoch 156/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.8573 - mae: 1.3072 - val_loss: 7.7891 - val_mae: 1.9704\n",
      "Epoch 157/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.7982 - mae: 1.3188 - val_loss: 7.7594 - val_mae: 1.9426\n",
      "Epoch 158/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.8026 - mae: 1.3331 - val_loss: 7.7059 - val_mae: 1.9229\n",
      "Epoch 159/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.7332 - mae: 1.2872 - val_loss: 7.6940 - val_mae: 1.9553\n",
      "Epoch 160/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.7816 - mae: 1.3270 - val_loss: 7.8198 - val_mae: 1.9347\n",
      "Epoch 161/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.9043 - mae: 1.3229 - val_loss: 8.8050 - val_mae: 1.9698\n",
      "Epoch 162/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.8651 - mae: 1.2948 - val_loss: 8.4358 - val_mae: 2.0141\n",
      "Epoch 163/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.7434 - mae: 1.3088 - val_loss: 7.9801 - val_mae: 1.9478\n",
      "Epoch 164/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.6383 - mae: 1.2658 - val_loss: 7.7105 - val_mae: 1.9223\n",
      "Epoch 165/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.5710 - mae: 1.2806 - val_loss: 7.6612 - val_mae: 1.9220\n",
      "Epoch 166/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.5148 - mae: 1.2369 - val_loss: 7.7776 - val_mae: 1.9090\n",
      "Epoch 167/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.4992 - mae: 1.2076 - val_loss: 7.6991 - val_mae: 1.9230\n",
      "Epoch 168/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.5207 - mae: 1.2283 - val_loss: 7.5990 - val_mae: 1.8930\n",
      "Epoch 169/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.5227 - mae: 1.2126 - val_loss: 7.9487 - val_mae: 1.9192\n",
      "Epoch 170/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.5038 - mae: 1.2130 - val_loss: 7.6522 - val_mae: 1.9134\n",
      "Epoch 171/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.4095 - mae: 1.2147 - val_loss: 7.5450 - val_mae: 1.8840\n",
      "Epoch 172/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3.4875 - mae: 1.2113 - val_loss: 7.5358 - val_mae: 1.8957\n",
      "Epoch 173/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3.4581 - mae: 1.2509 - val_loss: 7.6865 - val_mae: 1.9363\n",
      "Epoch 174/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.4643 - mae: 1.2605 - val_loss: 7.7318 - val_mae: 1.8911\n",
      "Epoch 175/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.4338 - mae: 1.1864 - val_loss: 7.5993 - val_mae: 1.8914\n",
      "Epoch 176/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.4215 - mae: 1.1975 - val_loss: 7.4299 - val_mae: 1.8916\n",
      "Epoch 177/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.4448 - mae: 1.2805 - val_loss: 7.7193 - val_mae: 1.8683\n",
      "Epoch 178/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.3349 - mae: 1.2028 - val_loss: 7.6221 - val_mae: 1.9025\n",
      "Epoch 179/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.3839 - mae: 1.2069 - val_loss: 7.4951 - val_mae: 1.8844\n",
      "Epoch 180/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.2505 - mae: 1.1984 - val_loss: 7.3542 - val_mae: 1.8750\n",
      "Epoch 181/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.2213 - mae: 1.1891 - val_loss: 7.2620 - val_mae: 1.8281\n",
      "Epoch 182/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.1700 - mae: 1.1702 - val_loss: 7.1508 - val_mae: 1.8386\n",
      "Epoch 183/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3.1419 - mae: 1.1908 - val_loss: 7.2200 - val_mae: 1.8729\n",
      "Epoch 184/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3.1892 - mae: 1.2018 - val_loss: 7.2980 - val_mae: 1.8396\n",
      "Epoch 185/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.2067 - mae: 1.1644 - val_loss: 7.1413 - val_mae: 1.8292\n",
      "Epoch 186/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3.1113 - mae: 1.1855 - val_loss: 7.1879 - val_mae: 1.8413\n",
      "Epoch 187/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.1290 - mae: 1.1273 - val_loss: 7.2691 - val_mae: 1.8024\n",
      "Epoch 188/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.0987 - mae: 1.1595 - val_loss: 6.9027 - val_mae: 1.7749\n",
      "Epoch 189/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.1047 - mae: 1.1948 - val_loss: 6.8003 - val_mae: 1.7597\n",
      "Epoch 190/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3.0442 - mae: 1.1339 - val_loss: 6.7848 - val_mae: 1.7719\n",
      "Epoch 191/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3.1298 - mae: 1.2131 - val_loss: 6.8377 - val_mae: 1.7474\n",
      "Epoch 192/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.0266 - mae: 1.1296 - val_loss: 6.8129 - val_mae: 1.7697\n",
      "Epoch 193/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.0401 - mae: 1.1666 - val_loss: 6.7608 - val_mae: 1.7817\n",
      "Epoch 194/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2.8988 - mae: 1.1264 - val_loss: 6.7434 - val_mae: 1.7459\n",
      "Epoch 195/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.9765 - mae: 1.1305 - val_loss: 6.6266 - val_mae: 1.7301\n",
      "Epoch 196/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.9134 - mae: 1.1229 - val_loss: 6.6906 - val_mae: 1.7451\n",
      "Epoch 197/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.9647 - mae: 1.1223 - val_loss: 6.8922 - val_mae: 1.7442\n",
      "Epoch 198/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.8805 - mae: 1.1243 - val_loss: 6.7034 - val_mae: 1.7511\n",
      "Epoch 199/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.8039 - mae: 1.1014 - val_loss: 6.8083 - val_mae: 1.7541\n",
      "Epoch 200/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.8283 - mae: 1.1212 - val_loss: 6.6929 - val_mae: 1.7376\n",
      "Epoch 201/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.0356 - mae: 1.1557 - val_loss: 6.7744 - val_mae: 1.7710\n",
      "Epoch 202/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.9908 - mae: 1.1781 - val_loss: 6.8877 - val_mae: 1.7683\n",
      "Epoch 203/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.7386 - mae: 1.1097 - val_loss: 6.6477 - val_mae: 1.7438\n",
      "Epoch 204/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.7140 - mae: 1.0738 - val_loss: 6.5965 - val_mae: 1.7325\n",
      "Epoch 205/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.7903 - mae: 1.1192 - val_loss: 6.5938 - val_mae: 1.7370\n",
      "Epoch 206/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.6611 - mae: 1.0696 - val_loss: 6.5456 - val_mae: 1.7292\n",
      "Epoch 207/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.7596 - mae: 1.0737 - val_loss: 6.5347 - val_mae: 1.7312\n",
      "Epoch 208/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.6484 - mae: 1.0779 - val_loss: 6.4284 - val_mae: 1.7123\n",
      "Epoch 209/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.7345 - mae: 1.1450 - val_loss: 6.3519 - val_mae: 1.7003\n",
      "Epoch 210/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.6306 - mae: 1.0770 - val_loss: 6.4089 - val_mae: 1.7060\n",
      "Epoch 211/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.6274 - mae: 1.0852 - val_loss: 6.5725 - val_mae: 1.7398\n",
      "Epoch 212/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.6371 - mae: 1.0496 - val_loss: 6.5464 - val_mae: 1.7265\n",
      "Epoch 213/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.5883 - mae: 1.0816 - val_loss: 6.5072 - val_mae: 1.7110\n",
      "Epoch 214/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.5551 - mae: 1.0280 - val_loss: 6.4885 - val_mae: 1.6973\n",
      "Epoch 215/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.5452 - mae: 1.0416 - val_loss: 6.3259 - val_mae: 1.6844\n",
      "Epoch 216/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2.4929 - mae: 1.0219 - val_loss: 6.3323 - val_mae: 1.6820\n",
      "Epoch 217/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.5712 - mae: 1.0600 - val_loss: 6.3672 - val_mae: 1.6893\n",
      "Epoch 218/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.4605 - mae: 1.0112 - val_loss: 6.3484 - val_mae: 1.6837\n",
      "Epoch 219/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.4564 - mae: 1.0191 - val_loss: 6.2203 - val_mae: 1.6573\n",
      "Epoch 220/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.4978 - mae: 1.0362 - val_loss: 6.3539 - val_mae: 1.6674\n",
      "Epoch 221/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.4812 - mae: 1.0034 - val_loss: 6.3201 - val_mae: 1.6760\n",
      "Epoch 222/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.4705 - mae: 1.0317 - val_loss: 6.2093 - val_mae: 1.6666\n",
      "Epoch 223/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.4618 - mae: 1.0174 - val_loss: 6.2725 - val_mae: 1.6734\n",
      "Epoch 224/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.4700 - mae: 1.0280 - val_loss: 6.1666 - val_mae: 1.6613\n",
      "Epoch 225/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.4368 - mae: 1.0332 - val_loss: 6.2811 - val_mae: 1.6799\n",
      "Epoch 226/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.3595 - mae: 1.0129 - val_loss: 6.0689 - val_mae: 1.6386\n",
      "Epoch 227/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.3353 - mae: 0.9830 - val_loss: 6.0480 - val_mae: 1.6332\n",
      "Epoch 228/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.3242 - mae: 0.9666 - val_loss: 6.1149 - val_mae: 1.6373\n",
      "Epoch 229/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.3707 - mae: 1.0297 - val_loss: 6.1136 - val_mae: 1.6473\n",
      "Epoch 230/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.3565 - mae: 1.0126 - val_loss: 6.2312 - val_mae: 1.6603\n",
      "Epoch 231/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.4286 - mae: 1.0070 - val_loss: 6.2835 - val_mae: 1.6732\n",
      "Epoch 232/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.3402 - mae: 1.0350 - val_loss: 6.1318 - val_mae: 1.6328\n",
      "Epoch 233/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.2644 - mae: 0.9624 - val_loss: 5.9395 - val_mae: 1.6248\n",
      "Epoch 234/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.9599 - mae: 1.3462 - val_loss: 6.0266 - val_mae: 1.7018\n",
      "Epoch 235/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.1117 - mae: 1.2127 - val_loss: 6.1046 - val_mae: 1.6981\n",
      "Epoch 236/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.4589 - mae: 1.0510 - val_loss: 5.8089 - val_mae: 1.6274\n",
      "Epoch 237/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.3594 - mae: 1.0083 - val_loss: 5.8031 - val_mae: 1.6152\n",
      "Epoch 238/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2.2627 - mae: 0.9820 - val_loss: 5.9000 - val_mae: 1.6101\n",
      "Epoch 239/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.2363 - mae: 0.9764 - val_loss: 5.7640 - val_mae: 1.5957\n",
      "Epoch 240/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.2772 - mae: 0.9847 - val_loss: 5.7453 - val_mae: 1.5962\n",
      "Epoch 241/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.2494 - mae: 1.0202 - val_loss: 5.6942 - val_mae: 1.5840\n",
      "Epoch 242/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.1557 - mae: 0.9551 - val_loss: 5.7513 - val_mae: 1.6001\n",
      "Epoch 243/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.1322 - mae: 0.9420 - val_loss: 5.7516 - val_mae: 1.5977\n",
      "Epoch 244/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.1205 - mae: 0.9338 - val_loss: 5.7106 - val_mae: 1.5871\n",
      "Epoch 245/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.1041 - mae: 0.9277 - val_loss: 5.7418 - val_mae: 1.5776\n",
      "Epoch 246/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.1192 - mae: 0.9535 - val_loss: 5.8476 - val_mae: 1.5912\n",
      "Epoch 247/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.1741 - mae: 0.9549 - val_loss: 5.8252 - val_mae: 1.6004\n",
      "Epoch 248/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.0742 - mae: 0.9432 - val_loss: 5.7160 - val_mae: 1.5789\n",
      "Epoch 249/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.0956 - mae: 0.9395 - val_loss: 5.6969 - val_mae: 1.5750\n",
      "Epoch 250/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.0649 - mae: 0.9214 - val_loss: 5.6742 - val_mae: 1.5911\n",
      "Epoch 251/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.0657 - mae: 0.9527 - val_loss: 5.6502 - val_mae: 1.5948\n",
      "Epoch 252/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.0512 - mae: 0.9610 - val_loss: 5.5599 - val_mae: 1.5613\n",
      "Epoch 253/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.0635 - mae: 0.9305 - val_loss: 5.7667 - val_mae: 1.5825\n",
      "Epoch 254/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2.1045 - mae: 0.9672 - val_loss: 5.9345 - val_mae: 1.6288\n",
      "Epoch 255/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.9820 - mae: 0.9069 - val_loss: 5.7093 - val_mae: 1.5746\n",
      "Epoch 256/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.9785 - mae: 0.9032 - val_loss: 5.6912 - val_mae: 1.5873\n",
      "Epoch 257/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.0115 - mae: 0.9556 - val_loss: 5.5443 - val_mae: 1.5552\n",
      "Epoch 258/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.9490 - mae: 0.9013 - val_loss: 5.6108 - val_mae: 1.5591\n",
      "Epoch 259/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.0391 - mae: 0.9566 - val_loss: 5.6769 - val_mae: 1.5665\n",
      "Epoch 260/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.9814 - mae: 0.9055 - val_loss: 5.5232 - val_mae: 1.5588\n",
      "Epoch 261/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.0033 - mae: 0.9470 - val_loss: 5.3757 - val_mae: 1.5373\n",
      "Epoch 262/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.9219 - mae: 0.9083 - val_loss: 5.4846 - val_mae: 1.5381\n",
      "Epoch 263/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.9710 - mae: 0.9021 - val_loss: 5.4644 - val_mae: 1.5337\n",
      "Epoch 264/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.9053 - mae: 0.8882 - val_loss: 5.4139 - val_mae: 1.5196\n",
      "Epoch 265/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.9021 - mae: 0.8849 - val_loss: 5.4135 - val_mae: 1.5074\n",
      "Epoch 266/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.8816 - mae: 0.8827 - val_loss: 5.3970 - val_mae: 1.5095\n",
      "Epoch 267/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.8947 - mae: 0.8925 - val_loss: 5.3543 - val_mae: 1.5087\n",
      "Epoch 268/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.9366 - mae: 0.9114 - val_loss: 5.4246 - val_mae: 1.5172\n",
      "Epoch 269/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.8313 - mae: 0.8863 - val_loss: 5.3903 - val_mae: 1.5383\n",
      "Epoch 270/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.4208 - mae: 1.0814 - val_loss: 5.6933 - val_mae: 1.6636\n",
      "Epoch 271/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2.3718 - mae: 1.0580 - val_loss: 5.5520 - val_mae: 1.5651\n",
      "Epoch 272/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.9891 - mae: 0.9448 - val_loss: 5.5853 - val_mae: 1.5827\n",
      "Epoch 273/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.9081 - mae: 0.9209 - val_loss: 5.2133 - val_mae: 1.5201\n",
      "Epoch 274/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.8542 - mae: 0.9014 - val_loss: 5.1558 - val_mae: 1.5058\n",
      "Epoch 275/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.9009 - mae: 0.9008 - val_loss: 5.2757 - val_mae: 1.5401\n",
      "Epoch 276/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.8892 - mae: 0.9130 - val_loss: 5.2119 - val_mae: 1.5132\n",
      "Epoch 277/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.7721 - mae: 0.8642 - val_loss: 5.3848 - val_mae: 1.5396\n",
      "Epoch 278/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.7852 - mae: 0.8814 - val_loss: 5.3230 - val_mae: 1.5515\n",
      "Epoch 279/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.9483 - mae: 0.9902 - val_loss: 5.2335 - val_mae: 1.4873\n",
      "Epoch 280/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.8003 - mae: 0.8981 - val_loss: 5.1996 - val_mae: 1.4853\n",
      "Epoch 281/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.8159 - mae: 0.9210 - val_loss: 5.0543 - val_mae: 1.4637\n",
      "Epoch 282/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.7116 - mae: 0.8416 - val_loss: 5.1226 - val_mae: 1.4621\n",
      "Epoch 283/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.7236 - mae: 0.8639 - val_loss: 5.0885 - val_mae: 1.4641\n",
      "Epoch 284/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.6859 - mae: 0.8322 - val_loss: 5.0299 - val_mae: 1.4619\n",
      "Epoch 285/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.6583 - mae: 0.8459 - val_loss: 5.0270 - val_mae: 1.4689\n",
      "Epoch 286/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.6463 - mae: 0.8290 - val_loss: 5.1629 - val_mae: 1.4882\n",
      "Epoch 287/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.6610 - mae: 0.8274 - val_loss: 5.2138 - val_mae: 1.5037\n",
      "Epoch 288/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.9128 - mae: 0.9576 - val_loss: 5.3579 - val_mae: 1.5355\n",
      "Epoch 289/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.7538 - mae: 0.9052 - val_loss: 5.1140 - val_mae: 1.4896\n",
      "Epoch 290/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.6167 - mae: 0.8337 - val_loss: 5.2625 - val_mae: 1.5103\n",
      "Epoch 291/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.6570 - mae: 0.8304 - val_loss: 5.1408 - val_mae: 1.4875\n",
      "Epoch 292/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.6227 - mae: 0.8123 - val_loss: 5.0910 - val_mae: 1.4876\n",
      "Epoch 293/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.6281 - mae: 0.8355 - val_loss: 5.0814 - val_mae: 1.4731\n",
      "Epoch 294/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.6209 - mae: 0.8215 - val_loss: 5.0199 - val_mae: 1.4729\n",
      "Epoch 295/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.5946 - mae: 0.8160 - val_loss: 4.9638 - val_mae: 1.4679\n",
      "Epoch 296/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.6121 - mae: 0.8346 - val_loss: 4.9947 - val_mae: 1.4520\n",
      "Epoch 297/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.5792 - mae: 0.8174 - val_loss: 5.0577 - val_mae: 1.4609\n",
      "Epoch 298/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.6230 - mae: 0.8399 - val_loss: 4.9939 - val_mae: 1.4768\n",
      "Epoch 299/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.7594 - mae: 0.9189 - val_loss: 5.0438 - val_mae: 1.4669\n",
      "Epoch 300/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.5941 - mae: 0.8527 - val_loss: 5.0010 - val_mae: 1.4495\n",
      "Epoch 301/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.6077 - mae: 0.8511 - val_loss: 4.9159 - val_mae: 1.4532\n",
      "Epoch 302/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.5793 - mae: 0.8428 - val_loss: 4.9667 - val_mae: 1.4646\n",
      "Epoch 303/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.6031 - mae: 0.8215 - val_loss: 5.0772 - val_mae: 1.4839\n",
      "Epoch 304/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.6096 - mae: 0.8516 - val_loss: 4.9450 - val_mae: 1.4511\n",
      "Epoch 305/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.4881 - mae: 0.7787 - val_loss: 4.8488 - val_mae: 1.4481\n",
      "Epoch 306/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.4570 - mae: 0.7834 - val_loss: 4.9452 - val_mae: 1.4593\n",
      "Epoch 307/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.6048 - mae: 0.8047 - val_loss: 4.9562 - val_mae: 1.4819\n",
      "Epoch 308/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.4721 - mae: 0.7973 - val_loss: 5.0230 - val_mae: 1.4820\n",
      "Epoch 309/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.4618 - mae: 0.7799 - val_loss: 4.9781 - val_mae: 1.4964\n",
      "Epoch 310/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.5023 - mae: 0.8026 - val_loss: 5.0543 - val_mae: 1.4845\n",
      "Epoch 311/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.5307 - mae: 0.8189 - val_loss: 5.0741 - val_mae: 1.4854\n",
      "Epoch 312/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.7417 - mae: 0.8572 - val_loss: 5.5390 - val_mae: 1.5532\n",
      "Epoch 313/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.5805 - mae: 0.8178 - val_loss: 5.1894 - val_mae: 1.4901\n",
      "Epoch 314/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.5645 - mae: 0.8095 - val_loss: 5.1778 - val_mae: 1.5270\n",
      "Epoch 315/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.4904 - mae: 0.8040 - val_loss: 5.1039 - val_mae: 1.5062\n",
      "Epoch 316/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.4153 - mae: 0.7944 - val_loss: 5.0671 - val_mae: 1.4916\n",
      "Epoch 317/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.4936 - mae: 0.8050 - val_loss: 5.0325 - val_mae: 1.4647\n",
      "Epoch 318/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.4759 - mae: 0.8068 - val_loss: 5.0141 - val_mae: 1.4651\n",
      "Epoch 319/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.4000 - mae: 0.7553 - val_loss: 5.0734 - val_mae: 1.4769\n",
      "Epoch 320/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.4646 - mae: 0.8066 - val_loss: 4.9714 - val_mae: 1.4616\n",
      "Epoch 321/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.4504 - mae: 0.7790 - val_loss: 5.0046 - val_mae: 1.4726\n",
      "Epoch 322/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.3865 - mae: 0.7766 - val_loss: 5.1354 - val_mae: 1.4810\n",
      "Epoch 323/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.3535 - mae: 0.7619 - val_loss: 4.9376 - val_mae: 1.4483\n",
      "Epoch 324/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.3370 - mae: 0.7529 - val_loss: 4.8289 - val_mae: 1.4270\n",
      "Epoch 325/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.4246 - mae: 0.7769 - val_loss: 4.9462 - val_mae: 1.4692\n",
      "Epoch 326/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.5009 - mae: 0.8252 - val_loss: 4.9894 - val_mae: 1.4825\n",
      "Epoch 327/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.5856 - mae: 0.8733 - val_loss: 5.0698 - val_mae: 1.4646\n",
      "Epoch 328/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.3432 - mae: 0.7579 - val_loss: 4.8759 - val_mae: 1.4422\n",
      "Epoch 329/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.3772 - mae: 0.7607 - val_loss: 4.9081 - val_mae: 1.4536\n",
      "Epoch 330/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.3923 - mae: 0.7663 - val_loss: 4.7848 - val_mae: 1.4251\n",
      "Epoch 331/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.3498 - mae: 0.7499 - val_loss: 4.8400 - val_mae: 1.4293\n",
      "Epoch 332/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.2924 - mae: 0.7439 - val_loss: 4.8912 - val_mae: 1.4382\n",
      "Epoch 333/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.3203 - mae: 0.7357 - val_loss: 4.9028 - val_mae: 1.4579\n",
      "Epoch 334/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.2510 - mae: 0.7213 - val_loss: 4.8535 - val_mae: 1.4474\n",
      "Epoch 335/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.2652 - mae: 0.7165 - val_loss: 4.8695 - val_mae: 1.4426\n",
      "Epoch 336/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.2522 - mae: 0.7013 - val_loss: 4.7962 - val_mae: 1.4448\n",
      "Epoch 337/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.2476 - mae: 0.7260 - val_loss: 4.8136 - val_mae: 1.4378\n",
      "Epoch 338/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.2301 - mae: 0.7049 - val_loss: 4.8396 - val_mae: 1.4410\n",
      "Epoch 339/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.2189 - mae: 0.7033 - val_loss: 4.8330 - val_mae: 1.4381\n",
      "Epoch 340/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.2203 - mae: 0.7059 - val_loss: 4.8828 - val_mae: 1.4466\n",
      "Epoch 341/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.2777 - mae: 0.7322 - val_loss: 4.9465 - val_mae: 1.4951\n",
      "Epoch 342/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.2176 - mae: 0.7088 - val_loss: 4.8128 - val_mae: 1.4564\n",
      "Epoch 343/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.2176 - mae: 0.7205 - val_loss: 4.9061 - val_mae: 1.4498\n",
      "Epoch 344/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.2302 - mae: 0.7229 - val_loss: 4.8474 - val_mae: 1.4635\n",
      "Epoch 345/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.2241 - mae: 0.7119 - val_loss: 4.8216 - val_mae: 1.4265\n",
      "Epoch 346/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.1845 - mae: 0.6879 - val_loss: 4.6722 - val_mae: 1.4249\n",
      "Epoch 347/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.1784 - mae: 0.7029 - val_loss: 4.7145 - val_mae: 1.4241\n",
      "Epoch 348/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.2104 - mae: 0.7075 - val_loss: 4.6400 - val_mae: 1.4014\n",
      "Epoch 349/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.1846 - mae: 0.6931 - val_loss: 4.6641 - val_mae: 1.4315\n",
      "Epoch 350/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.1671 - mae: 0.6915 - val_loss: 4.8202 - val_mae: 1.4260\n",
      "Epoch 351/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.2881 - mae: 0.7472 - val_loss: 4.8366 - val_mae: 1.4919\n",
      "Epoch 352/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.2398 - mae: 0.7511 - val_loss: 4.9124 - val_mae: 1.4809\n",
      "Epoch 353/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.1894 - mae: 0.7231 - val_loss: 4.7114 - val_mae: 1.4418\n",
      "Epoch 354/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.1439 - mae: 0.7106 - val_loss: 4.6507 - val_mae: 1.4234\n",
      "Epoch 355/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.1373 - mae: 0.6904 - val_loss: 4.7176 - val_mae: 1.4315\n",
      "Epoch 356/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.1273 - mae: 0.6829 - val_loss: 4.7945 - val_mae: 1.4310\n",
      "Epoch 357/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.3837 - mae: 0.7608 - val_loss: 4.6218 - val_mae: 1.4659\n",
      "Epoch 358/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.1540 - mae: 0.7112 - val_loss: 4.9168 - val_mae: 1.4748\n",
      "Epoch 359/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.1547 - mae: 0.6714 - val_loss: 4.5859 - val_mae: 1.4202\n",
      "Epoch 360/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.1274 - mae: 0.6738 - val_loss: 4.6092 - val_mae: 1.4168\n",
      "Epoch 361/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.0838 - mae: 0.6606 - val_loss: 4.6982 - val_mae: 1.4544\n",
      "Epoch 362/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.0909 - mae: 0.6579 - val_loss: 4.5840 - val_mae: 1.4238\n",
      "Epoch 363/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.0705 - mae: 0.6569 - val_loss: 4.6697 - val_mae: 1.4357\n",
      "Epoch 364/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.0805 - mae: 0.6755 - val_loss: 4.6975 - val_mae: 1.4284\n",
      "Epoch 365/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0720 - mae: 0.6763 - val_loss: 4.6935 - val_mae: 1.4203\n",
      "Epoch 366/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.0629 - mae: 0.6466 - val_loss: 4.6278 - val_mae: 1.4372\n",
      "Epoch 367/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.0807 - mae: 0.6759 - val_loss: 4.5931 - val_mae: 1.4061\n",
      "Epoch 368/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.0185 - mae: 0.6377 - val_loss: 4.6470 - val_mae: 1.4185\n",
      "Epoch 369/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.0614 - mae: 0.6724 - val_loss: 4.7777 - val_mae: 1.4432\n",
      "Epoch 370/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.0595 - mae: 0.6727 - val_loss: 4.6903 - val_mae: 1.4385\n",
      "Epoch 371/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.1182 - mae: 0.7006 - val_loss: 4.7787 - val_mae: 1.4194\n",
      "Epoch 372/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.0948 - mae: 0.6865 - val_loss: 4.7792 - val_mae: 1.4752\n",
      "Epoch 373/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.0771 - mae: 0.6704 - val_loss: 4.6771 - val_mae: 1.4450\n",
      "Epoch 374/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.0605 - mae: 0.6689 - val_loss: 4.8274 - val_mae: 1.4447\n",
      "Epoch 375/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.1118 - mae: 0.6827 - val_loss: 4.6270 - val_mae: 1.4465\n",
      "Epoch 376/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.0826 - mae: 0.7041 - val_loss: 4.6827 - val_mae: 1.4461\n",
      "Epoch 377/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.0759 - mae: 0.6931 - val_loss: 4.8604 - val_mae: 1.4783\n",
      "Epoch 378/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.0426 - mae: 0.6807 - val_loss: 4.6759 - val_mae: 1.4614\n",
      "Epoch 379/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.0439 - mae: 0.6676 - val_loss: 4.6265 - val_mae: 1.4173\n",
      "Epoch 380/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.0013 - mae: 0.6395 - val_loss: 4.4774 - val_mae: 1.4105\n",
      "Epoch 381/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.1313 - mae: 0.6818 - val_loss: 4.5341 - val_mae: 1.4405\n",
      "Epoch 382/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.0221 - mae: 0.6751 - val_loss: 4.8146 - val_mae: 1.4540\n",
      "Epoch 383/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.0835 - mae: 0.6915 - val_loss: 4.7206 - val_mae: 1.4527\n",
      "Epoch 384/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.3375 - mae: 0.8392 - val_loss: 4.6727 - val_mae: 1.4076\n",
      "Epoch 385/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.2487 - mae: 0.7413 - val_loss: 4.5895 - val_mae: 1.4034\n",
      "Epoch 386/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.0646 - mae: 0.6847 - val_loss: 4.5316 - val_mae: 1.4079\n",
      "Epoch 387/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.9774 - mae: 0.6428 - val_loss: 4.4795 - val_mae: 1.3913\n",
      "Epoch 388/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9676 - mae: 0.6310 - val_loss: 4.4569 - val_mae: 1.3959\n",
      "Epoch 389/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.9301 - mae: 0.6162 - val_loss: 4.4609 - val_mae: 1.3761\n",
      "Epoch 390/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.9067 - mae: 0.6006 - val_loss: 4.5143 - val_mae: 1.3678\n",
      "Epoch 391/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.0078 - mae: 0.6550 - val_loss: 4.4299 - val_mae: 1.4201\n",
      "Epoch 392/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.0084 - mae: 0.6559 - val_loss: 4.6327 - val_mae: 1.4281\n",
      "Epoch 393/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.9577 - mae: 0.6214 - val_loss: 4.5477 - val_mae: 1.4096\n",
      "Epoch 394/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.9028 - mae: 0.6056 - val_loss: 4.5451 - val_mae: 1.3934\n",
      "Epoch 395/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.8780 - mae: 0.5932 - val_loss: 4.5068 - val_mae: 1.4140\n",
      "Epoch 396/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.8728 - mae: 0.5853 - val_loss: 4.5314 - val_mae: 1.3803\n",
      "Epoch 397/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.9734 - mae: 0.6225 - val_loss: 4.3990 - val_mae: 1.3976\n",
      "Epoch 398/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.9154 - mae: 0.6345 - val_loss: 4.6549 - val_mae: 1.4181\n",
      "Epoch 399/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.8975 - mae: 0.6009 - val_loss: 4.5524 - val_mae: 1.4027\n",
      "Epoch 400/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.8689 - mae: 0.6031 - val_loss: 4.6581 - val_mae: 1.4255\n",
      "Epoch 401/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.9904 - mae: 0.6554 - val_loss: 4.6137 - val_mae: 1.4566\n",
      "Epoch 402/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.9006 - mae: 0.6401 - val_loss: 4.6251 - val_mae: 1.4434\n",
      "Epoch 403/500\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.8772 - mae: 0.6201 - val_loss: 4.5702 - val_mae: 1.4009\n",
      "Epoch 404/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.8512 - mae: 0.6112 - val_loss: 4.4954 - val_mae: 1.4023\n",
      "Epoch 405/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.9269 - mae: 0.6464 - val_loss: 4.7239 - val_mae: 1.4153\n",
      "Epoch 406/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.8666 - mae: 0.6128 - val_loss: 4.6175 - val_mae: 1.4352\n",
      "Epoch 407/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.8965 - mae: 0.6228 - val_loss: 4.6524 - val_mae: 1.4019\n",
      "Epoch 408/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.8676 - mae: 0.5950 - val_loss: 4.7886 - val_mae: 1.4245\n",
      "Epoch 409/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.3641 - mae: 0.8101 - val_loss: 5.3226 - val_mae: 1.5660\n",
      "Epoch 410/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.0681 - mae: 0.7197 - val_loss: 4.8486 - val_mae: 1.4584\n",
      "Epoch 411/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.9835 - mae: 0.6879 - val_loss: 5.1191 - val_mae: 1.5525\n",
      "Epoch 412/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.9913 - mae: 0.6714 - val_loss: 4.8295 - val_mae: 1.4528\n",
      "Epoch 413/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.8330 - mae: 0.5839 - val_loss: 4.6721 - val_mae: 1.4175\n",
      "Epoch 414/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.8048 - mae: 0.5689 - val_loss: 4.5362 - val_mae: 1.3827\n",
      "Epoch 415/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.8432 - mae: 0.5826 - val_loss: 4.5773 - val_mae: 1.3834\n",
      "Epoch 416/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.8242 - mae: 0.5761 - val_loss: 4.5975 - val_mae: 1.4138\n",
      "Epoch 417/500\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.8218 - mae: 0.5907 - val_loss: 4.5747 - val_mae: 1.3830\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data,train_labels,batch_size=32,epochs=500,validation_split=0.2,callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['mae'],label='train mae')\n",
    "plt.plot(history.history['val_mae'],label='val mae')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('mae')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.ylim([0,5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 667us/step - loss: 19.6202 - mae: 2.7319\n",
      "loss: 19.620\n",
      "mae: 2.732\n"
     ]
    }
   ],
   "source": [
    "test_loss,test_mae = model.evaluate(test_data,test_labels)\n",
    "print('loss: {:.3f}\\nmae: {:.3f}'.format(test_loss,test_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "前10筆測試標籤: [ 7. 19. 19. 27. 22. 24. 31. 23. 20. 23.]\n",
      "前10筆預測標籤: [ 8. 18. 22. 39. 25. 22. 27. 23. 20. 20.]\n"
     ]
    }
   ],
   "source": [
    "print('前10筆測試標籤:',np.round(test_labels[0:10]))\n",
    "test_predictions = model.predict(test_data[0:10]).flatten()\n",
    "print('前10筆預測標籤:',np.round(test_predictions))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d8a265d58268fc82dffe7ecb61fc57c8e1c6d6787d8b637cc4d52663ae128e42"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('crawler': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
